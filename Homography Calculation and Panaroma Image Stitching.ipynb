{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPK4mU9bBLrgA3ZTtghM6J/"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":2,"metadata":{"id":"Z9c1_Bood-d_","executionInfo":{"status":"ok","timestamp":1736075981689,"user_tz":-330,"elapsed":2,"user":{"displayName":"Hiteshi Meisheri","userId":"04356980078072161374"}}},"outputs":[],"source":["\n","import numpy as np\n","import cv2 as cv\n","import matplotlib.pyplot as plt\n","\n","imga='/content/sample_data/STA_0031.JPG'\n","imgb='/content/sample_data/STB_0032.JPG'\n","imgc='/content/sample_data/STC_0033.JPG'\n","imgd='/content/sample_data/STD_0034.JPG'\n","imge='/content/sample_data/STE_0035.JPG'\n","imgf='/content/sample_data/STF_0036.JPG'\n","\n","img_pairs=[[imga,imgb],[imgb,imgc],[imgc,imgd],[imgd,imge],[imge,imgf]]\n","\n","def plot_image(image_array):\n","  if type(image_array)==str:\n","    image_array=cv.imread(image_array)\n","  image_rgb = cv.cvtColor(image_array, cv.COLOR_BGR2RGB)\n","  plt.imshow(image_rgb)\n","  plt.axis('off')\n","  plt.show()"]},{"cell_type":"code","source":["\n","import numpy as np\n","import cv2 as cv\n","import matplotlib.pyplot as plt\n","\n","def calculate_homography(xy, x_y_):\n","        n = xy.shape[0]\n","        A = []\n","        for i in range(n):\n","            x, y = xy[i]\n","            u, v = x_y_[i]\n","            A.append([x, y, 1, 0, 0, 0, -u * x, -u * y, -u])\n","            A.append([0, 0, 0, x, y, 1, -v * x, -v * y, -v])\n","        A = np.array(A)\n","        U, S, V = np.linalg.svd(A)\n","        H = V[-1, :].reshape(3, 3)\n","        H = H / H[2, 2]\n","        return H\n","\n","def ransac(img1_path,img2_path, threshold, num_iterations):\n","    img1 = cv.imread(img1_path, cv.IMREAD_UNCHANGED)\n","    img2 = cv.imread(img2_path, cv.IMREAD_UNCHANGED)\n","\n","    sift = cv.SIFT_create()\n","    kp1, des1 = sift.detectAndCompute(img1, None)\n","    kp2, des2 = sift.detectAndCompute(img2, None)\n","\n","    bf = cv.BFMatcher()\n","    matches = bf.knnMatch(des1, des2, k=2)\n","    good = []\n","    for m, n in matches:\n","        if m.distance < 0.75 * n.distance:\n","            good.append([m])\n","\n","    xy = []\n","    x_y_ = []\n","    for i in good:\n","        indexa = i[0].queryIdx\n","        indexb = i[0].trainIdx\n","        xy.append(kp1[indexa].pt)\n","        x_y_.append(kp2[indexb].pt)\n","\n","    xy = np.array(xy)\n","    x_y_ = np.array(x_y_)\n","    best_H = None\n","    max_inliers = 0\n","    for _ in range(num_iterations):\n","        sample_indices = np.random.choice(xy.shape[0], 4, replace=False)\n","        sample_xy = xy[sample_indices]\n","        sample_x_y_ = x_y_[sample_indices]\n","        H = calculate_homography(sample_xy, sample_x_y_)\n","        inliers = 0\n","        for i in range(xy.shape[0]):\n","            x, y = xy[i]\n","            u, v = x_y_[i]\n","            p = np.array([x, y, 1])\n","            transformed_point = np.dot(H, p)\n","            transformed_point = transformed_point / transformed_point[2]\n","            error = np.linalg.norm(transformed_point[:2] - np.array([u, v]))\n","            if error < threshold:\n","                inliers += 1\n","        if inliers > max_inliers:\n","            max_inliers = inliers\n","            best_H = H\n","    return best_H, max_inliers\n","\n","def stitch_images(img1_path, img2_path, self):\n","    img1 = cv.imread(img1_path, cv.IMREAD_UNCHANGED)\n","    img2 = cv.imread(img2_path, cv.IMREAD_UNCHANGED)\n","\n","    sift = cv.SIFT_create()\n","    kp1, des1 = sift.detectAndCompute(img1, None)\n","    kp2, des2 = sift.detectAndCompute(img2, None)\n","\n","    bf = cv.BFMatcher()\n","    matches = bf.knnMatch(des1, des2, k=2)\n","    good = []\n","    for m, n in matches:\n","        if m.distance < 0.75 * n.distance:\n","            good.append([m])\n","\n","    xy = []\n","    x_y_ = []\n","    for i in good:\n","        indexa = i[0].queryIdx\n","        indexb = i[0].trainIdx\n","        xy.append(kp1[indexa].pt)\n","        x_y_.append(kp2[indexb].pt)\n","\n","    xy = np.array(xy)\n","    x_y_ = np.array(x_y_)\n","\n","    # def calculate_homography(xy, x_y_):\n","    #     n = xy.shape[0]\n","    #     A = []\n","    #     for i in range(n):\n","    #         x, y = xy[i]\n","    #         u, v = x_y_[i]\n","    #         A.append([x, y, 1, 0, 0, 0, -u * x, -u * y, -u])\n","    #         A.append([0, 0, 0, x, y, 1, -v * x, -v * y, -v])\n","    #     A = np.array(A)\n","    #     U, S, V = np.linalg.svd(A)\n","    #     H = V[-1, :].reshape(3, 3)\n","    #     H = H / H[2, 2]\n","    #     return H\n","\n","    # def ransac(xy, x_y_, threshold, num_iterations):\n","    #     best_H = None\n","    #     max_inliers = 0\n","    #     for _ in range(num_iterations):\n","    #         sample_indices = np.random.choice(xy.shape[0], 4, replace=False)\n","    #         sample_xy = xy[sample_indices]\n","    #         sample_x_y_ = x_y_[sample_indices]\n","    #         H = calculate_homography(sample_xy, sample_x_y_)\n","    #         inliers = 0\n","    #         for i in range(xy.shape[0]):\n","    #             x, y = xy[i]\n","    #             u, v = x_y_[i]\n","    #             p = np.array([x, y, 1])\n","    #             transformed_point = np.dot(H, p)\n","    #             transformed_point = transformed_point / transformed_point[2]\n","    #             error = np.linalg.norm(transformed_point[:2] - np.array([u, v]))\n","    #             if error < threshold:\n","    #                 inliers += 1\n","    #         if inliers > max_inliers:\n","    #             max_inliers = inliers\n","    #             best_H = H\n","    #     return best_H, max_inliers\n","\n","    #H_manual_ransac = ransac(xy, x_y_, threshold=5.0, num_iterations=1000)\n","    H_manual_ransac=ransacs[self]\n","    rows, cols = img1.shape[:2]\n","    coords = np.array([[0, 0, 1], [cols, 0, 1], [0, rows, 1], [cols, rows, 1]])\n","    warped_coords = np.dot(H_manual_ransac, coords.T).T\n","    warped_coords /= warped_coords[:, 2:3]\n","    all_coords = np.concatenate((coords, warped_coords))\n","    min_x = np.min(all_coords[:, 0])\n","    max_x = np.max(all_coords[:, 0])\n","    min_y = np.min(all_coords[:, 1])\n","    max_y = np.max(all_coords[:, 1])\n","    warped_canvas_size = (int(max_x - min_x), int(max_y - min_y))\n","    translation = np.array([[1, 0, -min_x], [0, 1, -min_y], [0, 0, 1]])\n","    print(translation)\n","    warped_img = cv.warpPerspective(img1, translation.dot(H_manual_ransac), warped_canvas_size)\n","    shifted_ref_img = cv.warpPerspective(img2, translation, warped_canvas_size)\n","\n","    def single_weights_array(size):\n","        if size % 2 == 1:\n","            return np.concatenate([np.linspace(0, 1, (size + 1) // 2), np.linspace(1, 0, (size + 1) // 2)[1:]])\n","        else:\n","            return np.concatenate([np.linspace(0, 1, size // 2), np.linspace(1, 0, size // 2)])\n","\n","    def single_weights_matrix(shape):\n","        return np.array(single_weights_array(shape[0])[:, np.newaxis] @ single_weights_array(shape[1])[:, np.newaxis].T)\n","\n","    mask = single_weights_matrix(shifted_ref_img.shape[:2])\n","    mask1 = cv.warpPerspective(mask, translation, warped_canvas_size)\n","    mask2 = cv.warpPerspective(mask, H_manual_ransac, warped_canvas_size)\n","    mask1 = mask1 / mask1.max()\n","    mask2 = mask2 / mask2.max()\n","    mask3 = np.divide(mask1, (mask1 + mask2), where=(mask1) != 0)\n","    mask3 = np.array([mask3, mask3, mask3]).transpose(1, 2, 0)\n","    mask3 = mask3 / mask3.max()\n","    masked_ref = mask3 * shifted_ref_img\n","    mask4 = np.divide(mask2, (mask1 + mask2), where=(mask2) != 0)\n","    mask4 = np.array([mask4, mask4, mask4]).transpose(1, 2, 0)\n","    mask4 = mask4 / mask4.max()\n","    masked_warped = (mask4) * warped_img\n","    added_image = masked_ref + masked_warped\n","\n","    return  added_image.astype(np.uint8)"],"metadata":{"id":"S9uWV7CEeLrA","executionInfo":{"status":"ok","timestamp":1736075983275,"user_tz":-330,"elapsed":11,"user":{"displayName":"Hiteshi Meisheri","userId":"04356980078072161374"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["ransacc=[]\n","\n","for i in img_pairs:\n","  current=np.array(ransac(i[0],i[1],5.0,1000)[0])\n","  ransacc.append(current)\n","  print(current.shape)\n","\n","\n","ransacs=[ransacc[0]]\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":347},"id":"VhYsa-PC8AQW","executionInfo":{"status":"error","timestamp":1736075983275,"user_tz":-330,"elapsed":10,"user":{"displayName":"Hiteshi Meisheri","userId":"04356980078072161374"}},"outputId":"56e6cf8f-ce41-4eb1-8c7e-7e4b4974b187"},"execution_count":4,"outputs":[{"output_type":"error","ename":"error","evalue":"OpenCV(4.10.0) /io/opencv/modules/features2d/src/sift.dispatch.cpp:512: error: (-5:Bad argument) image is empty or has incorrect depth (!=CV_8U) in function 'detectAndCompute'\n","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)","\u001b[0;32m<ipython-input-4-369134d9209b>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mimg_pairs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m   \u001b[0mcurrent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mransac\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m5.0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m   \u001b[0mransacc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcurrent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcurrent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-3-8aebc2689736>\u001b[0m in \u001b[0;36mransac\u001b[0;34m(img1_path, img2_path, threshold, num_iterations)\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0msift\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSIFT_create\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m     \u001b[0mkp1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdes1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msift\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetectAndCompute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m     \u001b[0mkp2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdes2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msift\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetectAndCompute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31merror\u001b[0m: OpenCV(4.10.0) /io/opencv/modules/features2d/src/sift.dispatch.cpp:512: error: (-5:Bad argument) image is empty or has incorrect depth (!=CV_8U) in function 'detectAndCompute'\n"]}]},{"cell_type":"code","source":["for i in range(len(ransacc)-1):\n","  ransacs.append(np.array(ransacc[i])@np.array(ransacc[i+1]))"],"metadata":{"id":"fXzglUkmCHrQ","executionInfo":{"status":"ok","timestamp":1736075994603,"user_tz":-330,"elapsed":1483,"user":{"displayName":"Hiteshi Meisheri","userId":"04356980078072161374"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"Z-M1y9yf9-i4","executionInfo":{"status":"aborted","timestamp":1736075983276,"user_tz":-330,"elapsed":8,"user":{"displayName":"Hiteshi Meisheri","userId":"04356980078072161374"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["result_images=[imga]\n","images=[imgb,imgc,imgd,imge,imgf]\n","\n","for i in range (0,2):\n","  prev=result_images[-1]\n","  path='/content/sample_data/'+str(i+1)+'.JPG'\n","  current=images[i]\n","  plot_image(current)\n","  added=stitch_images(prev,current,i)\n","  cv.imwrite(path,added)\n","  result_images.append(path)\n","  plot_image(added)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":347},"id":"fXTqNWVD8v37","outputId":"b5197817-b34c-4dd7-d40d-aa9f25def16d","executionInfo":{"status":"error","timestamp":1736075999385,"user_tz":-330,"elapsed":689,"user":{"displayName":"Hiteshi Meisheri","userId":"04356980078072161374"}}},"execution_count":6,"outputs":[{"output_type":"error","ename":"error","evalue":"OpenCV(4.10.0) /io/opencv/modules/imgproc/src/color.cpp:196: error: (-215:Assertion failed) !_src.empty() in function 'cvtColor'\n","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)","\u001b[0;32m<ipython-input-6-46e1c640928f>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m   \u001b[0mpath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'/content/sample_data/'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'.JPG'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m   \u001b[0mcurrent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m   \u001b[0mplot_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcurrent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m   \u001b[0madded\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstitch_images\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprev\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcurrent\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m   \u001b[0mcv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0madded\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-2-e065e595e5db>\u001b[0m in \u001b[0;36mplot_image\u001b[0;34m(image_array)\u001b[0m\n\u001b[1;32m     15\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_array\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mimage_array\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_array\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m   \u001b[0mimage_rgb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_array\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCOLOR_BGR2RGB\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m   \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_rgb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m   \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'off'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31merror\u001b[0m: OpenCV(4.10.0) /io/opencv/modules/imgproc/src/color.cpp:196: error: (-215:Assertion failed) !_src.empty() in function 'cvtColor'\n"]}]},{"cell_type":"code","source":["current=stitch_images(imga,imgb)\n","cv.imwrite('/content/sample_data/resultab.JPG', current)\n","alphabet=[imgc,imgd,imge,imgf]\n","plot_image(current)\n","path='/content/sample_data/resultab.JPG'\n","strings=['abc','abcd','abcde','abcdef']\n","\n","for i in range(0,4):\n","  current=stitch_images(path,alphabet[i])\n","  print(strings[i])\n","  plot_image(current)\n","  path='/content/sample_data/result'+strings[i]+'.jpg'\n","  cv.imwrite(path,current)"],"metadata":{"id":"2bIVbC9YeN24"},"execution_count":null,"outputs":[]}]}